{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "from transformers import BertTokenizer\n",
        "from torch.utils.data import TensorDataset\n",
        "from transformers import BertForSequenceClassification"
      ],
      "metadata": {
        "id": "XYxoSoXRCXG1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mLaVkVQ5IR7N"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('/content/mtsamples.csv')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols = [\"description\", \"sample_name\", \"keywords\", \"Unnamed: 0\"]\n",
        "df = df.drop(cols, axis='columns')\n",
        "df.head()"
      ],
      "metadata": {
        "id": "ojvjRy0eJW6z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.dropna(subset=['medical_specialty', 'transcription'])\n",
        "\n",
        "def clean_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text)\n",
        "    text = text.lower()\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "df['medical_specialty'] = df['medical_specialty'].apply(clean_text)\n",
        "df['transcription'] = df['transcription'].apply(clean_text)\n",
        "\n",
        "df.head()"
      ],
      "metadata": {
        "id": "dF_PjATgMdqR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['medical_specialty'].value_counts()"
      ],
      "metadata": {
        "id": "2862OKyQDHed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(df.index.values,\n",
        "                                                  df.label.values,\n",
        "                                                  test_size=0.15,\n",
        "                                                  random_state=42,\n",
        "                                                  stratify=df.label.values)\n",
        "\n",
        "df['data_type'] = ['not_set']*df.shape[0]\n",
        "\n",
        "df.loc[X_train, 'data_type'] = 'train'\n",
        "df.loc[X_val, 'data_type'] = 'val'\n",
        "\n",
        "df.groupby(['Conference', 'label', 'data_type']).count()"
      ],
      "metadata": {
        "id": "QVyRPsdNMdmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "model = AutoModelForSequenceClassification.from_pretrained('dmis-lab/biobert-v1.1', num_labels=2)\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=64,\n",
        "    warmup_steps=500,\n",
        "    weight_decay=0.01,\n",
        "    logging_dir='./logs',\n",
        ")\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=(input_ids, attention_mask, df['label']),\n",
        ")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "GqjLRpejD99C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\",\n",
        "                                                      num_labels=len(label_dict),\n",
        "                                                      output_attentions=False,\n",
        "                                                      output_hidden_states=False)"
      ],
      "metadata": {
        "id": "LkM_nYGxEHm1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}